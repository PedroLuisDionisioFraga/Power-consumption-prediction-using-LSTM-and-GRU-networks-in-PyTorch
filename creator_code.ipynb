{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas a serem usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão do 'torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o caminho do repositório cujas informações serão usadas para treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos um total de 12 arquivos .csv contendo dados de tendência de energia horária ('est_hourly.paruqet' e 'pjm_hourly_est.csv' não são usados). Em nossa próxima etapa, estaremos lendo esses arquivos e pré-processando esses dados nesta ordem:\n",
    "\n",
    "Obtendo os dados de tempo de cada passo de tempo individual e generalizando-os:\n",
    "\n",
    " * Hora do dia, ou seja, 0-23\n",
    " * Dia da semana, ou seja, 1-7\n",
    " * Mês, ou seja, 1-12\n",
    " * Dia do ano, ou seja, 1-365\n",
    "\n",
    "Escale os dados para valores entre 0 e 1:\n",
    " * Os algoritmos tendem a ter um desempenho melhor ou convergir mais rapidamente quando os recursos estão em uma escala relativamente semelhante e/ou próxima da distribuição normal.\n",
    " * A escala preserva a forma da distribuição original e não reduz a importância dos outliers\n",
    "\n",
    "Agrupe os dados em sequências para serem usadas como entradas para o modelo e armazene seus rótulos correspondentes.\n",
    "\n",
    " * O comprimento da sequência ou período window_size é o número de pontos de dados no histórico que o modelo usará para fazer a previsão.\n",
    " * O rótulo será o próximo ponto de dados no tempo após o último na sequência de entrada.\n",
    "As entradas e rótulos serão então divididos em conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sliding_window(data, window_size, inputs_cols_indices, label_col_index):\n",
    "  \"\"\"\n",
    "    data: matriz numpy incluindo dados\n",
    "    window_size: tamanho da janela\n",
    "    inputs_cols_indices: índices de colunas para incluir\n",
    "  \"\"\"\n",
    "\n",
    "  # (# instances created by movement, seq_len (timestamps), # features (input_len))\n",
    "  inputs = np.zeros((len(data) - window_size, window_size, len(inputs_cols_indices)))\n",
    "  labels = np.zeros(len(data) - window_size)\n",
    "\n",
    "  for i in range(window_size, len(data)):\n",
    "    inputs[i - window_size] = data[i - window_size : i, inputs_cols_indices]\n",
    "    labels[i - window_size] = data[i, label_col_index]\n",
    "  inputs = inputs.reshape(-1, window_size, len(inputs_cols_indices))\n",
    "  labels = labels.reshape(-1, 1)\n",
    "  print(inputs.shape, labels.shape)\n",
    "\n",
    "  return inputs, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acelerar as coisas, usarei apenas arquivos num_files_for_dataset .csv para criar meu conjunto de dados. Sinta-se à vontade para executá-lo você mesmo com todo o conjunto de dados, se tiver tempo e capacidade de computação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col_index = 0  # consumption as label to predict\n",
    "inputs_cols_indices = range(5)\n",
    "# use (consumption, hour, dayofweek, month, dayofyear) columns as features\n",
    "\n",
    "# Define window_size period and split inputs/labels\n",
    "window_size = 90\n",
    "\n",
    "# The scaler objects will be stored in this dictionary so that our output test data from the model can be re-scaled during evaluation\n",
    "label_scalers = {}\n",
    "\n",
    "train_x = []\n",
    "test_x = {}\n",
    "test_y = {}\n",
    "\n",
    "# Skipping the files we're not using\n",
    "processing_files = [\n",
    "  file for file in os.listdir(data_dir) if os.path.splitext(file)[1] == \".csv\"\n",
    "]\n",
    "\n",
    "num_files_for_dataset = 5\n",
    "\n",
    "for file in tqdm_notebook(processing_files[:num_files_for_dataset]):\n",
    "  print(f\"Processing {file} ...\")\n",
    "  # Armazenar arquivo csv em um Pandas DataFrame\n",
    "  df = pd.read_csv(os.path.join(data_dir, file), parse_dates=[\"Datetime\"])\n",
    "\n",
    "  # Processing the time data into suitable input formats\n",
    "  df[\"hour\"] = df.apply(lambda x: x[\"Datetime\"].hour, axis=1)\n",
    "  df[\"dayofweek\"] = df.apply(lambda x: x[\"Datetime\"].dayofweek, axis=1)\n",
    "  df[\"month\"] = df.apply(lambda x: x[\"Datetime\"].month, axis=1)\n",
    "  df[\"dayofyear\"] = df.apply(lambda x: x[\"Datetime\"].dayofyear, axis=1)\n",
    "  df = df.sort_values(\"Datetime\").drop(\"Datetime\", axis=1)\n",
    "\n",
    "  # Scaling the input data\n",
    "  sc = MinMaxScaler()\n",
    "  label_sc = MinMaxScaler()\n",
    "  data = sc.fit_transform(df.values)\n",
    "\n",
    "  # Obtaining the scaler for the labels(usage data) so that output can be\n",
    "  # re-scaled to actual value during evaluation\n",
    "  label_sc.fit(df.iloc[:, label_col_index].values.reshape(-1, 1))\n",
    "  label_scalers[file] = label_sc\n",
    "\n",
    "  # Move the window\n",
    "  inputs, labels = move_sliding_window(\n",
    "    data,\n",
    "    window_size,\n",
    "    inputs_cols_indices=inputs_cols_indices,\n",
    "    label_col_index=label_col_index,\n",
    "  )\n",
    "\n",
    "  # CONCAT created instances from all .csv files.\n",
    "  # Split data into train/test portions and combining all data from different files into a single array\n",
    "  test_portion = int(0.1 * len(inputs))\n",
    "  if len(train_x) == 0:  # first iteration\n",
    "    train_x = inputs[:-test_portion]\n",
    "    train_y = labels[:-test_portion]\n",
    "  else:\n",
    "    train_x = np.concatenate((train_x, inputs[:-test_portion]))\n",
    "    train_y = np.concatenate((train_y, labels[:-test_portion]))\n",
    "    test_x[file] = inputs[-test_portion:]\n",
    "    test_y[file] = labels[-test_portion:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregadores/geradores de dados Pytorch\n",
    "Para melhorar a velocidade do nosso treinamento, podemos processar os dados em lotes para que o modelo não precise atualizar seus pesos com tanta frequência. As classes TensorDataset e DataLoader são úteis para dividir nossos dados em lotes e embaralhá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "\n",
    "# Drop the last incomplete batch\n",
    "train_loader = DataLoader(\n",
    "  train_data, shuffle=True, batch_size=batch_size, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "  f\"Train Size: {train_x.shape}, Batch Size: {batch_size}, # of iterations per epoch: {int(train_x.shape[0]/batch_size)}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liberando memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x, train_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando sua GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se uma GPU está disponível no sistema\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Se tivermos uma GPU disponível, configuraremos nosso dispositivo para GPU. Usaremos essa variável de dispositivo posteriormente em nosso código.\n",
    "#device = torch.device(\"cuda\")  # Use isso para obrigar a IA rodar na GPU\n",
    "if is_cuda:\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"GPU is available\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"CPU is available\")\n",
    "print(f\"O tipo do device é {device.type}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Implementa, na classe GRUNet, uma rede neural GRU com uma camada totalmente conectada (fully-connected) na saída, enquanto a classe LSTMNet implementa uma rede neural LSTM com a mesma camada totalmente conectada na saída. Ambos os modelos recebem uma entrada x e um estado oculto inicial h e retornam uma saída out e um estado oculto final h.\n",
    " * As funções \"init_hidden\" são responsáveis por inicializar o estado oculto inicial com zeros para ser usado na primeira etapa de previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "    super(GRUNet, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    # Inicializa a camada GRU com as dimensões fornecidas e as opções de dropout\n",
    "    self.gru = nn.GRU(\n",
    "        input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n",
    "    )\n",
    "    # Inicializa a camada fully connected com as dimensões fornecidas\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    # Inicializa a função de ativação ReLU\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x, h):\n",
    "    # Executa a camada GRU com entrada x e estado oculto h\n",
    "    out, h = self.gru(x, h)\n",
    "    # print(out[:, -1].shape, h.shape)\n",
    "    # Seleciona o estado oculto correspondente ao último timestamp da sequência (t=90) (1024, 256)\n",
    "    out = self.fc(self.relu(out[:, -1]))  # out[:, -1, :]\n",
    "    # print(out.shape) # (1024, 1)\n",
    "    # Retorna a saída e o estado oculto\n",
    "    return out, h\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    # Inicializa o estado oculto h_0 com zeros\n",
    "    weight = next(self.parameters()).data\n",
    "    hidden = (\n",
    "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "    )\n",
    "    return hidden\n",
    "\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "    super(LSTMNet, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    # Inicializa a camada LSTM com as dimensões fornecidas e as opções de dropout\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n",
    "    )\n",
    "    # Inicializa a camada fully connected com as dimensões fornecidas\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    # Inicializa a função de ativação ReLU\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x, h):\n",
    "    # Executa a camada LSTM com entrada x e estado oculto h\n",
    "    out, h = self.lstm(x, h)\n",
    "    # Seleciona o estado oculto correspondente ao último timestamp da sequência\n",
    "    out = self.fc(self.relu(out[:, -1]))\n",
    "    # Retorna a saída e o estado oculto\n",
    "    return out, h\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    weight = next(self.parameters()).data\n",
    "    # Inicializa o estado oculto h_0 e o estado da célula c_0 com zeros\n",
    "    hidden = (\n",
    "      weight.new(self.n_layers, batch_size, self.hidden_dim)\n",
    "     .zero_()\n",
    "     .to(device),  # h_0\n",
    "     weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "    )\n",
    "    return hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função train é responsável por treinar o modelo com os dados de treinamento fornecidos pelo train_loader, com o objetivo de minimizar a função de perda nn.MSELoss() (Erro Quadrático Médio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  train_loader,\n",
    "  learn_rate,\n",
    "  hidden_dim=256,\n",
    "  n_layers=2,  # Número de camadas da rede\n",
    "  n_epochs=5,  # Número de épocas\n",
    "  model_type=\"GRU\",  # Tipo de modelo\n",
    "  print_every=100,  # Me mostra a cada 100 BATCH's\n",
    "):\n",
    "  \n",
    "  # Obtendo o tamanho da entrada a partir do primeiro batch do dataloader\n",
    "  input_dim = next(iter(train_loader))[0].shape[2]  # 5\n",
    "\n",
    "  # Batch generator (train_data, train_label)\n",
    "  # print(next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape) # torch.Size([1024, 90, 5]) torch.Size([1024, 1])\n",
    "\n",
    "  # Definindo a saída como uma única dimensão\n",
    "  output_dim = 1\n",
    "\n",
    "  # Instanciando o modelo, escolhendo entre GRU e LSTM\n",
    "  if model_type == \"GRU\":\n",
    "    model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "  else:\n",
    "    model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "  \n",
    "  # Movendo o modelo para a GPU, se estiver disponível\n",
    "  model.to(device)\n",
    "\n",
    "  # Definindo a função de perda como Mean Squared Error (Erro Médio Quadrático)\n",
    "  criterion = nn.MSELoss()  # Mean Squared Error\n",
    "  # Definindo o otimizador como Adam com a taxa de aprendizado especificada\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "  # Colocando o modelo em modo de treinamento\n",
    "  model.train()\n",
    "  # Imprimindo mensagem de início do treinamento\n",
    "  print(\"Starting Training of {} model\".format(model_type))\n",
    "  epoch_times = []\n",
    "\n",
    "  # Iniciando o loop de treinamento por épocas\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    # Inicializando o hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    avg_loss = 0.0\n",
    "    counter = 0\n",
    "\n",
    "    # Iterando pelos batches do dataloader\n",
    "    for x, label in train_loader:\n",
    "      counter += 1\n",
    "\n",
    "      # Reinicializando o hidden state, se necessário\n",
    "      if model_type == \"GRU\":\n",
    "        h = h.data\n",
    "      # Unpack both h_0 and c_0\n",
    "      elif model_type == \"LSTM\":\n",
    "        h = tuple([e.data for e in h])\n",
    "\n",
    "      # Zerando os gradientes antes de executar o backpropagation\n",
    "      # pois o PyTorch acumula os gradientes nas passadas subsequentes para trás\n",
    "      model.zero_grad()\n",
    "\n",
    "      # Passando a entrada pelo modelo\n",
    "      out, h = model(x.to(device).float(), h)\n",
    "      # Calculando a perda\n",
    "      loss = criterion(out, label.to(device).float())\n",
    "\n",
    "      # Perform backpropragation\n",
    "      # Executando o backpropagation\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculando a média das perdas\n",
    "      avg_loss += loss.item()\n",
    "\n",
    "      # Imprimindo o status do treinamento a cada 'print_every' batches\n",
    "      if counter % print_every == 0:\n",
    "        print(\n",
    "          f\"Epoch {epoch} - Step: {counter}/{len(train_loader)} - Average Loss for Epoch: {avg_loss/counter}\"\n",
    "        )\n",
    "    current_time = time.process_time()\n",
    "\n",
    "    # Imprimindo informações sobre a época atual\n",
    "    print(f\"Epoch {epoch}/{n_epochs} Done, Total Loss: {avg_loss/len(train_loader)}\")\n",
    "    print(f\"Time Elapsed for Epoch: {current_time-start_time} seconds\")\n",
    "\n",
    "    epoch_times.append(current_time - start_time)\n",
    "\n",
    "  # Imprimindo informações sobre o tempo total de treinamento\n",
    "  print(f\"Total Training Time: {sum(epoch_times)} seconds\")\n",
    "\n",
    "  # Retornando o modelo treinado\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis usadas para treinar os RMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len = 90  # (timestamps)\n",
    "n_hidden = 256\n",
    "n_layers = 2\n",
    "n_epochs = 1\n",
    "print_every = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = train(\n",
    "  train_loader,\n",
    "  learn_rate=lr,\n",
    "  hidden_dim=n_hidden,\n",
    "  n_layers=n_layers,\n",
    "  n_epochs=n_epochs,\n",
    "  model_type=\"GRU\",\n",
    "  print_every=print_every,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gru_model.state_dict(), \"./models/gru_model.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando e salvando um modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = train(\n",
    "  train_loader,\n",
    "  learn_rate=lr,\n",
    "  hidden_dim=n_hidden,\n",
    "  n_layers=n_layers,\n",
    "  n_epochs=n_epochs,\n",
    "  model_type=\"LSTM\",\n",
    "  print_every=print_every,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model.state_dict(), \"./models/lstm_model.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "input_dim = 5\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "lstm_model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "lstm_model.load_state_dict(torch.load(\"./models/lstm_model.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(outputs, targets):\n",
    "  sMAPE = (\n",
    "    100\n",
    "    / len(targets)\n",
    "    * np.sum(np.abs(outputs - targets) / (np.abs(outputs + targets)) / 2)\n",
    "  )\n",
    "  return sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "  model.eval()\n",
    "  outputs = []\n",
    "  targets = []\n",
    "  start_time = time.process_time()\n",
    "  # get data of test data for each state\n",
    "  for file in test_x.keys():\n",
    "    inputs = torch.from_numpy(np.array(test_x[file]))\n",
    "    labels = torch.from_numpy(np.array(test_y[file]))\n",
    "\n",
    "    h = model.init_hidden(inputs.shape[0])\n",
    "\n",
    "    # predict outputs\n",
    "    with torch.no_grad():\n",
    "      out, h = model(inputs.to(device).float(), h)\n",
    "\n",
    "    outputs.append(\n",
    "      label_scalers[file]\n",
    "      .inverse_transform(out.cpu().detach().numpy())\n",
    "      .reshape(-1)\n",
    "    )\n",
    "\n",
    "    targets.append(\n",
    "      label_scalers[file].inverse_transform(labels.numpy()).reshape(-1)\n",
    "    )\n",
    "\n",
    "  # Merge all files\n",
    "  concatenated_outputs = np.concatenate(outputs)\n",
    "  concatenated_targets = np.concatenate(targets)\n",
    "\n",
    "  print(f\"Evaluation Time: {time.process_time()-start_time}\")\n",
    "  print(f\"sMAPE: {round(sMAPE(concatenated_outputs, concatenated_targets), 3)}%\")\n",
    "\n",
    "  # list of of targets/outputs for each state\n",
    "  return outputs, targets, sMAPE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avalie o desempenho da GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avalie o desempenho do LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_outputs, targets, lstm_sMAPE = evaluate(lstm_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gru_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo algumas visualizações em conjuntos aleatórios de nossa saída prevista versus os dados de consumo real para alguns estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = list(test_x.keys())\n",
    "states_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[0][-100:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[0]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(gru_outputs[1][-50:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[1][-50:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[1][-50:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[1]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(gru_outputs[2][:50], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[2][:50], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[2][:50], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[2]} state\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(gru_outputs[3][:100], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[3][:100], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[3][:100], color=\"b\", label=\"Actual\")\n",
    "plt.title(f\"Energy Consumption for {states_list[3]} state\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "Embora o modelo GRU possa ter cometido erros menores e superado ligeiramente o modelo LSTM em termos de sMAPE (erro percentual médio absoluto simétrico), a diferença é insignificante e, portanto, inconclusiva. Houve muitos outros testes conduzidos por outros comparando esses dois modelos, mas não houve um vencedor claro sobre qual é a melhor arquitetura geral. Parece que os modelos são amplamente bem-sucedidos em prever as tendências do consumo de energia. Embora eles ainda possam errar algumas mudanças, como atrasos na previsão de uma queda no consumo, as previsões seguem muito de perto a linha real no conjunto de teste. Isso se deve à natureza dos dados de consumo de energia e ao fato de que existem padrões e mudanças cíclicas que o modelo pode considerar. Problemas de previsão de séries temporais mais difíceis, como previsão de preço de ações ou previsão de volume de vendas, podem ter dados que são amplamente aleatórios ou não têm padrões previsíveis e, nesses casos, a precisão será definitivamente menor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
