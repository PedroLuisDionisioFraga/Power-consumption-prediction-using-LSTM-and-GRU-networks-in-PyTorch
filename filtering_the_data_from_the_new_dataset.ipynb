{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulando dados no excel\n",
    "\n",
    "Usaremos 2 bibliotecas para manipulação de dados:\n",
    " * [openpyxl](https://openpyxl.readthedocs.io/en/stable/)\n",
    " * [pandas](https://pandas.pydata.org/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usaremos agora a **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicando o arquivo em excel\n",
    "_Obs:_ É possível usar tanto extensões od tipo \".xlsx\" e \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workSpace = pd.read_excel(\"data/municipio_mensal.xlsx\", sheet_name=\"Consumo MWh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos ver o tamanho da planilha usando o método \"shape()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4512, 353)\n"
     ]
    }
   ],
   "source": [
    "print(workSpace.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos retirar as colunas que não nos interessam, como:\n",
    " * tipo \n",
    " * cod_muni\n",
    " * agência\n",
    " * núcleo\n",
    " * unidade\n",
    " * cod_classe\n",
    " * município (Após a filtragem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantendo no DataFrame apenas os dados com município igual a Florianópolis\n",
    "workSpace = workSpace.loc[workSpace[\"município\"] == \"Florianópolis\"]\n",
    "# Removendo as colunas que não serão utilizadas em nossa análise\n",
    "workSpace = workSpace.drop(columns=['tipo', 'cod_muni', 'agência', 'núcleo', 'unidade', 'cod_classe', 'município'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora possuímos apenas dados referentes ao município de Florianópolis. Porém a distribuição destes dados no DataFrame não está de forma ideal para analisá-los. Utilizaremos a função **melt()** para despivotar a tabela utilizando a coluna classe como referência, assim alterando o formato de **wide** para **long**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando a feature classe como ponto de pivotamento, assim tendo o DataFrame corretamente construído\n",
    "df_floripa = workSpace.melt(id_vars=['classe'])\n",
    "\n",
    "# Renomeando as colunas restantes para refletir o que estamos analisando\n",
    "df_floripa.rename(columns = {'variable':'Data','value':'MWh'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos separar os dados de consumo em relação a sua classe, criando um DataFrame para cada uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados de consumo pela classe em diferentes DataFrames\n",
    "df_res = df_floripa.loc[df_floripa['classe'] == 'Residencial']\n",
    "df_ind = df_floripa.loc[df_floripa['classe'] == 'Industrial']\n",
    "df_com = df_floripa.loc[df_floripa['classe'] == 'Comercial']\n",
    "df_rur = df_floripa.loc[df_floripa['classe'] == 'Rural']\n",
    "df_pub = df_floripa.loc[df_floripa['classe'] == 'Poder Público']\n",
    "df_ilu = df_floripa.loc[df_floripa['classe'] == 'Iluminação Pública']\n",
    "df_ser = df_floripa.loc[df_floripa['classe'] == 'Serviço Público']\n",
    "df_pro = df_floripa.loc[df_floripa['classe'] == 'Próprio']\n",
    "\n",
    "#print(df_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrando ainda mais\n",
    " * Removendo a coluna \"classe\"\n",
    " * Somando todos os valores da coluna \"MWh\" que possuem as datas da coluna \"Data\" iguais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos perceber acima, as linhas de consumo se repetem, mesmo pertencendo a mesma classe. Assim utilizaremos a função utilizando as funções **groupby()** e **sum()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.groupby(['Data'], as_index=False).sum()\n",
    "df_ind = df_ind.groupby(['Data'], as_index=False).sum()\n",
    "df_com = df_com.groupby(['Data'], as_index=False).sum()\n",
    "df_rur = df_rur.groupby(['Data'], as_index=False).sum()\n",
    "df_pub = df_pub.groupby(['Data'], as_index=False).sum()\n",
    "df_ilu = df_ilu.groupby(['Data'], as_index=False).sum()\n",
    "df_ser = df_ser.groupby(['Data'], as_index=False).sum()\n",
    "df_pro = df_pro.groupby(['Data'], as_index=False).sum()\n",
    "#print(df_com)\n",
    "\n",
    "#print(df_res[\"Data\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removendo a coluna \"Data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renomeando a coluna \"Data\" para \"Datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_ind = df_ind.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_com = df_com.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_rur = df_rur.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_pub = df_pub.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_ilu = df_ilu.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_ser = df_ser.rename(columns={\"Data\": \"Datetime\"})\n",
    "df_pro = df_pro.rename(columns={\"Data\": \"Datetime\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Criando a coluna \"Time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.insert(2, \"Time\", \"00:00:00\")\n",
    "df_ind.insert(2, \"Time\", \"00:00:00\")\n",
    "df_com.insert(2, \"Time\", \"00:00:00\")\n",
    "df_rur.insert(2, \"Time\", \"00:00:00\")\n",
    "df_pub.insert(2, \"Time\", \"00:00:00\")\n",
    "df_ilu.insert(2, \"Time\", \"00:00:00\")\n",
    "df_ser.insert(2, \"Time\", \"00:00:00\")\n",
    "df_pro.insert(2, \"Time\", \"00:00:00\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertendo para o formato \".csv\"\n",
    "\n",
    "1) Concatenando as colunas \"Datetime\", \"Time\" e \"MWh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_concat = pd.concat([df_res[\"Datetime\"], df_res[\"Time\"], df_res[\"MWh\"]], axis=1)\n",
    "df_ind_concat = pd.concat([df_ind[\"Datetime\"], df_ind[\"Time\"], df_ind[\"MWh\"]], axis=1)\n",
    "df_com_concat = pd.concat([df_com[\"Datetime\"], df_com[\"Time\"], df_com[\"MWh\"]], axis=1)\n",
    "df_rur_concat = pd.concat([df_rur[\"Datetime\"], df_rur[\"Time\"], df_rur[\"MWh\"]], axis=1)\n",
    "df_pub_concat = pd.concat([df_pub[\"Datetime\"], df_pub[\"Time\"], df_pub[\"MWh\"]], axis=1)\n",
    "df_ilu_concat = pd.concat([df_ilu[\"Datetime\"], df_ilu[\"Time\"], df_ilu[\"MWh\"]], axis=1)\n",
    "df_ser_concat = pd.concat([df_ser[\"Datetime\"], df_ser[\"Time\"], df_ser[\"MWh\"]], axis=1)\n",
    "df_pro_concat = pd.concat([df_pro[\"Datetime\"], df_pro[\"Time\"], df_pro[\"MWh\"]], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Renomeando o nome da coluna de \"Datetime,Time,MWh\" para \"Datetime,MWh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_concat = df_res_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_ind_concat = df_ind_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_com_concat = df_com_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_rur_concat = df_rur_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_pub_concat = df_pub_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_ilu_concat = df_ilu_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_ser_concat = df_ser_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})\n",
    "df_pro_concat = df_pro_concat.rename(columns={\"Datetime,Time,MWh\": \"Datetime,MWh\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Datetime      Time          MWh\n",
      "0   1994-01-01  00:00:00  21357.14700\n",
      "1   1994-02-01  00:00:00  20782.78500\n",
      "2   1994-03-01  00:00:00  19920.44200\n",
      "3   1994-04-01  00:00:00  19890.39500\n",
      "4   1994-05-01  00:00:00  19409.53900\n",
      "..         ...       ...          ...\n",
      "340 2022-05-01  00:00:00  49513.31500\n",
      "341 2022-06-01  00:00:00  51371.37700\n",
      "342 2022-07-01  00:00:00  50536.92089\n",
      "343 2022-08-01  00:00:00  50106.64000\n",
      "344 2022-09-01  00:00:00  50833.49600\n",
      "\n",
      "[345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_res_concat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Removendo a vírgula entre a data e a hora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Convertendo no formato \".csv\" e salvando os modelos filtrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as alterações concatenadas\n",
    "df_res_concat.to_csv(\"data/After Filters/res_municipio_mensal.csv\", index=False)\n",
    "df_ind_concat.to_csv(\"data/After Filters/ind_municipio_mensal.csv\", index=False)\n",
    "df_com_concat.to_csv(\"data/After Filters/com_municipio_mensal.csv\", index=False)\n",
    "df_rur_concat.to_csv(\"data/After Filters/rur_municipio_mensal.csv\", index=False)\n",
    "df_pub_concat.to_csv(\"data/After Filters/pub_municipio_mensal.csv\", index=False)\n",
    "df_ilu_concat.to_csv(\"data/After Filters/ilu_municipio_mensal.csv\", index=False)\n",
    "df_ser_concat.to_csv(\"data/After Filters/ser_municipio_mensal.csv\", index=False)\n",
    "df_pro_concat.to_csv(\"data/After Filters/pro_municipio_mensal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Datetime      Time          MWh\n",
      "0    1994-01-01  00:00:00  21357.14700\n",
      "1    1994-02-01  00:00:00  20782.78500\n",
      "2    1994-03-01  00:00:00  19920.44200\n",
      "3    1994-04-01  00:00:00  19890.39500\n",
      "4    1994-05-01  00:00:00  19409.53900\n",
      "..          ...       ...          ...\n",
      "340  2022-05-01  00:00:00  49513.31500\n",
      "341  2022-06-01  00:00:00  51371.37700\n",
      "342  2022-07-01  00:00:00  50536.92089\n",
      "343  2022-08-01  00:00:00  50106.64000\n",
      "344  2022-09-01  00:00:00  50833.49600\n",
      "\n",
      "[345 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Datetime,Time,MWh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Datetime,Time,MWh'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/After Filters/res_municipio_mensal.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(df)\n\u001b[1;32m----> 3\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mDatetime,Time,MWh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mDatetime,Time,MWh\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m,0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_res_concat\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/After Filters/res_municipio_mensal.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/After Filters/ind_municipio_mensal.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3761\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Datetime,Time,MWh'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/After Filters/res_municipio_mensal.csv\")\n",
    "print(df)\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_res_concat.to_csv(\"data/After Filters/res_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/ind_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_ind_concat.to_csv(\"data/After Filters/ind_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/com_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_com_concat.to_csv(\"data/After Filters/com_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/rur_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_rur_concat.to_csv(\"data/After Filters/rur_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/pub_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_pub_concat.to_csv(\"data/After Filters/pub_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/ilu_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_ilu_concat.to_csv(\"data/After Filters/ilu_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/ser_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_ser_concat.to_csv(\"data/After Filters/ser_municipio_mensal.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"data/After Filters/pro_municipio_mensal.csv\")\n",
    "df[\"Datetime,MWh\"] = df[\"Datetime,MWh\"].str.replace(\",0\", \" 0\")\n",
    "df_pro_concat.to_csv(\"data/After Filters/pro_municipio_mensal.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
